{
 "cells": [
  {
   "cell_type": "raw",
   "id": "e2049daa",
   "metadata": {},
   "source": [
    "Author: Fahim Anzum\n",
    "Version: 1.0\n",
    "Last Updated: June 5, 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1aa9043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting praw\n",
      "  Downloading praw-7.7.1-py3-none-any.whl (191 kB)\n",
      "Collecting prawcore<3,>=2.1\n",
      "  Downloading prawcore-2.4.0-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: websocket-client>=0.54.0 in c:\\users\\anzum\\anaconda3\\envs\\py39\\lib\\site-packages (from praw) (0.58.0)\n",
      "Requirement already satisfied: update-checker>=0.18 in c:\\users\\anzum\\anaconda3\\envs\\py39\\lib\\site-packages (from praw) (0.18.0)\n",
      "Requirement already satisfied: requests<3.0,>=2.6.0 in c:\\users\\anzum\\anaconda3\\envs\\py39\\lib\\site-packages (from prawcore<3,>=2.1->praw) (2.27.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\anzum\\anaconda3\\envs\\py39\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\anzum\\anaconda3\\envs\\py39\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\anzum\\anaconda3\\envs\\py39\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\anzum\\anaconda3\\envs\\py39\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (2021.10.8)\n",
      "Requirement already satisfied: six in c:\\users\\anzum\\anaconda3\\envs\\py39\\lib\\site-packages (from websocket-client>=0.54.0->praw) (1.16.0)\n",
      "Installing collected packages: prawcore, praw\n",
      "Successfully installed praw-7.7.1 prawcore-2.4.0\n"
     ]
    }
   ],
   "source": [
    "## Install praw for scrapping data from Reddit\n",
    "!pip3 install praw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ae5845a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import praw\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from prawcore import NotFound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d095c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reddit API credentials\n",
    "reddit = praw.Reddit(\n",
    "    client_id = , # Add your cliet ID\n",
    "    client_secret = , # Add your secret key\n",
    "    user_agent = 'Scrapper 1.0 by /u/anzumbivor', # Format is: 'Scrapper version_number by reddit_username'\n",
    "    username = , # Add your username\n",
    "    password = # Add your password\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7432d956",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_reddit(keywords, subreddits, start_date, end_date):\n",
    "    \"\"\"\n",
    "    Search Reddit posts and comments based on multiple keywords, subreddits, date range, and region.\n",
    "    \n",
    "    :param keywords: List of keywords to search for\n",
    "    :param subreddits: List of subreddits to search within\n",
    "    :param start_date: Start date in the format 'YYYY-MM-DD'\n",
    "    :param end_date: End date in the format 'YYYY-MM-DD'\n",
    "    :return: DataFrame with the results\n",
    "    \"\"\"\n",
    "    # Convert dates to Unix timestamps\n",
    "    start_timestamp = int(datetime.strptime(start_date, '%Y-%m-%d').timestamp())\n",
    "    end_timestamp = int(datetime.strptime(end_date, '%Y-%m-%d').timestamp())\n",
    "\n",
    "    data = []\n",
    "\n",
    "    for subreddit in subreddits:\n",
    "        for keyword in keywords:\n",
    "            try:\n",
    "                for submission in reddit.subreddit(subreddit).search(keyword, limit=None, time_filter='all'):\n",
    "                    if start_timestamp <= submission.created_utc <= end_timestamp:\n",
    "                        # Fetch comments for each submission\n",
    "                        submission.comments.replace_more(limit=None)\n",
    "                        comments = []\n",
    "                        for comment in submission.comments.list():\n",
    "                            if start_timestamp <= comment.created_utc <= end_timestamp:\n",
    "                                comments.append({\n",
    "                                    'Comment_Text': comment.body,\n",
    "                                    'Comment_Created_UTC': comment.created_utc,\n",
    "                                    'Comment_Score': comment.score\n",
    "                                })\n",
    "\n",
    "                        data.append({\n",
    "                            'Keyword': keyword,\n",
    "                            'Subreddit': subreddit,\n",
    "                            'Title': submission.title,\n",
    "                            'Text': submission.selftext,\n",
    "                            'Created_UTC': submission.created_utc,\n",
    "                            'Score': submission.score,\n",
    "                            'Num_Comments': submission.num_comments,\n",
    "                            'URL': submission.url,\n",
    "                            'Comments': comments\n",
    "                        })\n",
    "            except NotFound:\n",
    "                print(f\"Subreddit {subreddit} not found or inaccessible.\")\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred while processing subreddit {subreddit} with keyword {keyword}: {e}\")\n",
    "\n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec1624b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "keywords = ['health', 'trust', 'maternal', 'underrepresented']  # Add your list of keywords here\n",
    "# subreddits = ['CanadaHealth', 'CanadianHealthcare', 'HealthCanada', 'Canada',\n",
    "#               'BabyBumpsCanada', 'CanadianParents', 'Parenting',\n",
    "#               'IndigenousCanada', 'FirstNations', 'BlackCanada', 'NewcomersCanada', 'LGBTCanada']  # Add your list of subreddits here\n",
    "\n",
    "subreddits = ['BabyBumpsCanada', 'CanadianParents',\n",
    "              'IndigenousCanada', 'lgbtcanada',\n",
    "              'alberta', 'AlbertaHealthServices', 'AskACanadian', 'ontario', \n",
    "              'publichealth', 'ottawa', 'britishcolumbia', 'Manitoba', 'saskatchewan', 'NovaScotia',\n",
    "              'newfoundland', 'nunavut', 'PEI', 'newbrunswickcanada', 'canada',\n",
    "              'FirstNationsCanada']  # Add your list of subreddits here\n",
    "\n",
    "start_date = '2023-01-01'\n",
    "end_date = '2023-12-31'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a891c9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data\n",
    "df = search_reddit(keywords, subreddits, start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caac5de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expand the comments to separate rows while maintaining the post information\n",
    "expanded_rows = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    post_info = {\n",
    "        'Keyword': row['Keyword'],\n",
    "        'Subreddit': row['Subreddit'],\n",
    "        'Title': row['Title'],\n",
    "        'Text': row['Text'],\n",
    "        'Created_UTC': row['Created_UTC'],\n",
    "        'Score': row['Score'],\n",
    "        'Num_Comments': row['Num_Comments'],\n",
    "        'URL': row['URL']\n",
    "    }\n",
    "    if row['Comments']:\n",
    "        for comment in row['Comments']:\n",
    "            expanded_row = post_info.copy()\n",
    "            expanded_row.update(comment)\n",
    "            expanded_rows.append(expanded_row)\n",
    "    else:\n",
    "        expanded_rows.append(post_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73cf9d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame from the expanded rows\n",
    "expanded_df = pd.DataFrame(expanded_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6503f278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write code to inspect the scrapped data from the dataframe\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82f6102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by post details to count the number of comments per post\n",
    "posts_with_comment_counts = expanded_df.groupby(['Keyword', 'Subreddit', 'Title', 'Text', 'Created_UTC', 'Score', 'Num_Comments', 'URL']).size().reset_index(name='Comment_Count')\n",
    "# Print the result\n",
    "posts_with_comment_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1ea7ee",
   "metadata": {},
   "source": [
    "# Visualizing the Scrapped Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccf8917",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Group by subreddit and count the number of comments per subreddit\n",
    "subreddit_comment_counts = expanded_df.groupby('Subreddit').size().reset_index(name='Comment_Count')\n",
    "\n",
    "# Sort the data by Comment_Count\n",
    "subreddit_comment_counts = subreddit_comment_counts.sort_values(by='Comment_Count', ascending=False)\n",
    "\n",
    "# Set up the plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(data=subreddit_comment_counts, x='Subreddit', y='Comment_Count', palette='viridis')\n",
    "\n",
    "# Customize the plot\n",
    "plt.title('Number of Comments per Subreddit')\n",
    "plt.xlabel('Subreddit')\n",
    "plt.ylabel('Number of Comments')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f859ed72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by keyword and count the number of comments per keyword\n",
    "keyword_comment_counts = expanded_df.groupby('Keyword').size().reset_index(name='Comment_Count')\n",
    "\n",
    "# Sort the data by Comment_Count\n",
    "keyword_comment_counts = keyword_comment_counts.sort_values(by='Comment_Count', ascending=False)\n",
    "\n",
    "# Set up the plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "plot = sns.barplot(data=keyword_comment_counts, x='Keyword', y='Comment_Count', palette='viridis')\n",
    "\n",
    "# Add numbers on top of each bar\n",
    "for index, row in keyword_comment_counts.iterrows():\n",
    "    plot.text(index, row.Comment_Count, row.Comment_Count, color='black', ha=\"center\")\n",
    "\n",
    "# Customize the plot\n",
    "plt.title('Number of Comments per Keyword')\n",
    "plt.xlabel('Keyword')\n",
    "plt.ylabel('Number of Comments')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f017ab",
   "metadata": {},
   "source": [
    "#### ***Note: Before storing the data into a csv file, please remove the rows where there are no comments for any particular reddit posts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618be0c1",
   "metadata": {},
   "source": [
    "# Save the Data to CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22b0596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV\n",
    "expanded_df.to_csv('FA_reddit_posts_and_comments_Jun2.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
